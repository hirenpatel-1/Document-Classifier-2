{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for pretty print to all vars\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\" #default=\"last_expr\"\n",
    "\n",
    "#to_display_any_htmls\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StorParam=dict()\n",
    "StorParam['hparams']=dict()\n",
    "StorParam['metrics']=dict()\n",
    "StorParam['filesMisClf']=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADD', 'BUY', 'EPG']  Total files read: 710\n"
     ]
    }
   ],
   "source": [
    "#Change dir to read dataset files from zip's extract\n",
    "import os\n",
    "os.chdir('C:/Users/mihir.parikh/PyNb/wk_data_op/')\n",
    "files=list()\n",
    "categories=[fl for fl in os.listdir('.') if os.path.isdir(fl)]\n",
    "for folder in categories:\n",
    "        files+=[folder+'/'+p for p in os.listdir(folder)]\n",
    "print(categories,\" Total files read:\",len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 files ignored. New Dataset has 706 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BUY/reg-level_19CSR-RS30-61-105_The Day Care Provider and Other Day Care Personnel.xml.txt',\n",
       " 'EPG/45,911.pdf.txt',\n",
       " 'EPG/171006_Protections.pdf.txt',\n",
       " 'EPG/45,910.pdf.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess file's text_contents before laoding to pandas dataframe\n",
    "import re\n",
    "dataF={'content':[],'catg':[]}\n",
    "newfiles=[]\n",
    "#adding to dataFrame after preprocessing:\n",
    "#    [remove 1st few not null lines, remove files of less than 10 chars, merge concurrent spaces lines,etc]\n",
    "skip1stLines=2\n",
    "for fi in files:\n",
    "    with open(fi,encoding=\"utf8\") as f:\n",
    "        #print(\"for file\",fi)\n",
    "        PREPROC=f.read()\n",
    "        #make non-space similar to space\n",
    "        PREPROC=PREPROC.replace('Â ',' ') #care...left side wala asli space nai hai\n",
    "        while PREPROC.count('  '):PREPROC=PREPROC.replace('  ',' ')\n",
    "        while PREPROC.count('\\n '):PREPROC=PREPROC.replace('\\n ','\\n')\n",
    "        while PREPROC.count(' \\n'):PREPROC=PREPROC.replace(' \\n','\\n')\n",
    "        while PREPROC.count('\\n\\n'):PREPROC=PREPROC.replace('\\n\\n','\\n')\n",
    "        PREPROC=' '.join(PREPROC.split('\\n')[0 if fi.startswith('Others') else skip1stLines:])\n",
    "        #PREPROC=re.sub(r\"\\d+(\\.\\d*)?\", r\"\",PREPROC) #remove all numbers (digits)\n",
    "        PREPROC=re.sub(r\"[(](\\S*?)[)]\", r\"\",PREPROC) #remove all b/w (brackets)\n",
    "        PREPROC=re.sub(r\"[^a-zA-Z ]\", r\"\",PREPROC) #remove all non alpha (brackets)\n",
    "        while PREPROC.count('  '):PREPROC=PREPROC.replace('  ',' ')\n",
    "        if len(PREPROC)<10:continue\n",
    "        dataF['content'].append(PREPROC)\n",
    "        dataF['catg'].append(fi.split('/')[-2])\n",
    "        newfiles.append(fi)\n",
    "skippedfiles=list(set(files)-set(newfiles))\n",
    "print(len(skippedfiles),\"files ignored. New Dataset has\",len(newfiles),\"files.\")\n",
    "##check skip files of some catg\n",
    "#sorted(list(filter((lambda st:st.startswith('MC')),skippedfiles)))\n",
    "\n",
    "StorParam['files']=files\n",
    "StorParam['newfiles']=newfiles\n",
    "StorParam['preproc_comment']=\"default\"\n",
    "\n",
    "skippedfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPG    291\n",
      "ADD    261\n",
      "BUY    154\n",
      "Name: catg, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>EPG</td>\n",
       "      <td>Wasbtngton October MEMORANDUM FOR ALL COMPONEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>EPG</td>\n",
       "      <td>UNITED STATES DISTRICT COURT FOR THE DISTRICT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>EPG</td>\n",
       "      <td>UNITED STATES COURT OF APPEALS FOR THE NINTH C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>EPG</td>\n",
       "      <td>UNITED STATES COURT OF APPEALS FOR THE NINTH C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>EPG</td>\n",
       "      <td>United States Court of Appeals For the Seventh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADD</td>\n",
       "      <td>MIDDLE DISTRICT OF FLORIDA TAMPA DIVISION KENN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADD</td>\n",
       "      <td>UNITED STATES DISTRICT COURT EASTERN DISTRICT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADD</td>\n",
       "      <td>DISTRICT OF MINNESOTA James Chavira Plaintiff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADD</td>\n",
       "      <td>UNITED STATES COURT OF APPEALS TENTH CIRCUIT K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADD</td>\n",
       "      <td>DISTRICT OF KANSAS Equal Employment Opportunit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>BUY</td>\n",
       "      <td>CFR The average unweighted amount and average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>BUY</td>\n",
       "      <td>IN THE SUPREME COURT OF PENNSYLVANIA WESTERN D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>BUY</td>\n",
       "      <td>IN THE SUPREME COURT OF PENNSYLVANIA WESTERN D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>BUY</td>\n",
       "      <td>RELATES TO KRS Chapter STATUTORY AUTHORITY KRS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>BUY</td>\n",
       "      <td>January Term FILED June No released at pm RORY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load to pandas dataframe and have a peek on each catg\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(dataF)\n",
    "print(df['catg'].value_counts())\n",
    "for k in df['catg'].value_counts().keys():display(HTML(df[(df['catg']==k)].head(5).to_html()))\n",
    "\n",
    "StorParam['catg_val_count']=df['catg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [(353,), (353,)] Test [(211,), (211,)] CV [(142,), (142,)]\n"
     ]
    }
   ],
   "source": [
    "#partial import of sklearn. will full load sub-modules as needed.\n",
    "import sklearn\n",
    "\n",
    "#split data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df['content']\n",
    "Y=df['catg']\n",
    "SplitRatios=(.5,.3,.2) #train test cv\n",
    "#SplitRatio_ts=0.4\n",
    "SplitRatio_ts=sum(SplitRatios[1:])#1-SplitRatios[0]\n",
    "#SplitRatio_cv=0.5\n",
    "SplitRatio_cv=SplitRatios[-1]/SplitRatio_ts\n",
    "\n",
    "\n",
    "Random_ts=42\n",
    "Random_cv=420\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=SplitRatio_ts,random_state=Random_ts)\n",
    "X_test,X_cv,Y_test,Y_cv=sklearn.model_selection.train_test_split(X_test,Y_test,test_size=SplitRatio_cv,random_state=Random_cv)\n",
    "print(\"Train\",[X_train.shape,Y_train.shape],\"Test\",[X_test.shape,Y_test.shape],\"CV\",[X_cv.shape,Y_cv.shape])\n",
    "#now data is ready\n",
    "StorParam['SplitRatio_ts']=SplitRatio_ts\n",
    "StorParam['SplitRatio_cv']=SplitRatio_cv\n",
    "StorParam['Random_ts']=Random_ts\n",
    "StorParam['Random_cv']=Random_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Accuracy\n",
      "TRAIN 1.0\n",
      "TEST 0.8957345971563981\n",
      "--> Train MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  misses in TrainData\n",
      "--> Test MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>89</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.values[ 13 ] Predicted EPG Actual ADD File:[errI=149 ADD/17-120.pdf.txt ]\n",
      "X_test.values[ 31 ] Predicted ADD Actual EPG File:[errI=587 EPG/45752.pdf.txt ]\n",
      "X_test.values[ 37 ] Predicted EPG Actual BUY File:[errI=382 BUY/RocheleauElder.pdf.txt ]\n",
      "X_test.values[ 45 ] Predicted ADD Actual EPG File:[errI=692 EPG/45868.pdf.txt ]\n",
      "X_test.values[ 46 ] Predicted EPG Actual ADD File:[errI=179 ADD/17-150.pdf.txt ]\n",
      "X_test.values[ 58 ] Predicted EPG Actual BUY File:[errI=284 BUY/BuenoLR.pdf.txt ]\n",
      "X_test.values[ 59 ] Predicted EPG Actual ADD File:[errI=133 ADD/17-103.pdf.txt ]\n",
      "X_test.values[ 67 ] Predicted EPG Actual ADD File:[errI=78 ADD/17-043.pdf.txt ]\n",
      "X_test.values[ 95 ] Predicted EPG Actual ADD File:[errI=163 ADD/17-134.pdf.txt ]\n",
      "X_test.values[ 96 ] Predicted EPG Actual BUY File:[errI=338 BUY/MaddenMidland.pdf.txt ]\n",
      "X_test.values[ 101 ] Predicted EPG Actual ADD File:[errI=136 ADD/17-106.pdf.txt ]\n",
      "X_test.values[ 104 ] Predicted ADD Actual EPG File:[errI=674 EPG/45849.pdf.txt ]\n",
      "X_test.values[ 107 ] Predicted EPG Actual ADD File:[errI=73 ADD/17-038.pdf.txt ]\n",
      "X_test.values[ 118 ] Predicted EPG Actual BUY File:[errI=349 BUY/MossFirstPremier.pdf.txt ]\n",
      "X_test.values[ 119 ] Predicted ADD Actual EPG File:[errI=655 EPG/45830.pdf.txt ]\n",
      "X_test.values[ 127 ] Predicted EPG Actual BUY File:[errI=319 BUY/GraySeterus.pdf.txt ]\n",
      "X_test.values[ 128 ] Predicted EPG Actual BUY File:[errI=333 BUY/JohnsonPushpin.pdf.txt ]\n",
      "X_test.values[ 134 ] Predicted EPG Actual BUY File:[errI=344 BUY/McMahonLVNV.pdf.txt ]\n",
      "X_test.values[ 143 ] Predicted EPG Actual BUY File:[errI=367 BUY/PedigoRobertson.pdf.txt ]\n",
      "X_test.values[ 161 ] Predicted ADD Actual EPG File:[errI=481 EPG/45,937.pdf.txt ]\n",
      "X_test.values[ 174 ] Predicted ADD Actual EPG File:[errI=428 EPG/45,882.pdf.txt ]\n",
      "X_test.values[ 204 ] Predicted ADD Actual EPG File:[errI=567 EPG/45732.pdf.txt ]\n",
      "22  misses in TestData\n"
     ]
    }
   ],
   "source": [
    "#pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "algoname='nb'\n",
    "#naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf_nb = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3))),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=0.01))\n",
    "                    ])\n",
    "clfname='text_clf_'+algoname\n",
    "StorParam['hparams'][algoname]={x:globals()[clfname].named_steps[x].get_params() for x in globals()[clfname].named_steps.keys()}\n",
    "#fit_transforms of data to pipeline\n",
    "fit_nb=text_clf_nb.fit(X_train,Y_train)\n",
    "\n",
    "#testing model\n",
    "trscr=text_clf_nb.score(X_train,Y_train)\n",
    "tsscr=text_clf_nb.score(X_test,Y_test)\n",
    "print(\"--> Accuracy\")\n",
    "print(\"TRAIN\",trscr)\n",
    "print(\"TEST\",tsscr)\n",
    "StorParam['metrics'][algoname]={'train':trscr,'test':tsscr,'cv':None}\n",
    "StorParam['filesMisClf'][algoname]={'train':list(),'test':list(),'cv':list()}\n",
    "#misClassifications\n",
    "print(\"--> Train MisClassification\")\n",
    "TRpredicted_nb = text_clf_nb.predict(X_train)\n",
    "misClTr_nb=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_train,TRpredicted_nb,rownames=[\"True\"],colnames=[\"Train_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TRpredicted_nb)):\n",
    "    if TRpredicted_nb[i]!=Y_train.iloc[i]:\n",
    "        print(\"X_Train.values[\",i,\"] Predicted\",TRpredicted_nb[i],\"Actual\",Y_train.iloc[i],\n",
    "              \"File:[errI=\"+str(X_train.index[i]),newfiles[X_train.index[i]],\"]\")\n",
    "        misClTr_nb.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['train'].append(newfiles[X_train.index[i]])\n",
    "print(len(misClTr_nb),\" misses in TrainData\")\n",
    "print(\"--> Test MisClassification\")\n",
    "TSpredicted_nb = text_clf_nb.predict(X_test)\n",
    "misClTs_nb=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_test,TSpredicted_nb,rownames=[\"True\"],colnames=[\"Test_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TSpredicted_nb)):\n",
    "    if TSpredicted_nb[i]!=Y_test.iloc[i]:\n",
    "        print(\"X_test.values[\",i,\"] Predicted\",TSpredicted_nb[i],\"Actual\",Y_test.iloc[i],\n",
    "              \"File:[errI=\"+str(X_test.index[i]),newfiles[X_test.index[i]],\"]\")\n",
    "        misClTs_nb.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['test'].append(newfiles[X_test.index[i]])\n",
    "print(len(misClTs_nb),\" misses in TestData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#study misclassified doc errI [by filename or errI_index]\n",
    "#errI=newfiles.index('MC-275/0001553350-17-000313-4.txt')\n",
    "errI=35\n",
    "#print(errI,\"TESTdata\" if errI in X_test else \"TRAINdata\",newfiles[errI],X_test.get(errI,0) or X_train.get(errI,0))\n",
    "#os.system(\"np++ \"+newfiles[errI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM SVC [C-Support Vector Classification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Accuracy\n",
      "TRAIN 1.0\n",
      "TEST 0.933649289099526\n",
      "--> Train MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  misses in TrainData\n",
      "--> Test MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.values[ 13 ] Predicted EPG Actual ADD File:[errI=149 ADD/17-120.pdf.txt ]\n",
      "X_test.values[ 31 ] Predicted ADD Actual EPG File:[errI=587 EPG/45752.pdf.txt ]\n",
      "X_test.values[ 37 ] Predicted EPG Actual BUY File:[errI=382 BUY/RocheleauElder.pdf.txt ]\n",
      "X_test.values[ 45 ] Predicted ADD Actual EPG File:[errI=692 EPG/45868.pdf.txt ]\n",
      "X_test.values[ 46 ] Predicted EPG Actual ADD File:[errI=179 ADD/17-150.pdf.txt ]\n",
      "X_test.values[ 58 ] Predicted EPG Actual BUY File:[errI=284 BUY/BuenoLR.pdf.txt ]\n",
      "X_test.values[ 95 ] Predicted EPG Actual ADD File:[errI=163 ADD/17-134.pdf.txt ]\n",
      "X_test.values[ 127 ] Predicted EPG Actual BUY File:[errI=319 BUY/GraySeterus.pdf.txt ]\n",
      "X_test.values[ 134 ] Predicted EPG Actual BUY File:[errI=344 BUY/McMahonLVNV.pdf.txt ]\n",
      "X_test.values[ 152 ] Predicted EPG Actual ADD File:[errI=247 ADD/17-218.pdf.txt ]\n",
      "X_test.values[ 174 ] Predicted ADD Actual EPG File:[errI=428 EPG/45,882.pdf.txt ]\n",
      "X_test.values[ 178 ] Predicted EPG Actual ADD File:[errI=108 ADD/17-073.pdf.txt ]\n",
      "X_test.values[ 195 ] Predicted EPG Actual BUY File:[errI=411 BUY/WVCode.mht.txt ]\n",
      "X_test.values[ 204 ] Predicted ADD Actual EPG File:[errI=567 EPG/45732.pdf.txt ]\n",
      "14  misses in TestData\n"
     ]
    }
   ],
   "source": [
    "#pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "algoname='svm'\n",
    "#svm_svc\n",
    "from sklearn.svm import SVC\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3), )),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC(decision_function_shape=\"ovo\", C = 1000000, kernel='rbf', gamma ='auto'))\n",
    "                    ])\n",
    "\n",
    "clfname='text_clf_'+algoname\n",
    "StorParam['hparams'][algoname]={x:globals()[clfname].named_steps[x].get_params() for x in globals()[clfname].named_steps.keys()}\n",
    "#fit_transforms of data to pipeline\n",
    "fit_svm=text_clf_svm.fit(X_train,Y_train)\n",
    "\n",
    "#testing model\n",
    "trscr=text_clf_svm.score(X_train,Y_train)\n",
    "tsscr=text_clf_svm.score(X_test,Y_test)\n",
    "print(\"--> Accuracy\")\n",
    "print(\"TRAIN\",trscr)\n",
    "print(\"TEST\",tsscr)\n",
    "StorParam['metrics'][algoname]={'train':trscr,'test':tsscr,'cv':None}\n",
    "StorParam['filesMisClf'][algoname]={'train':list(),'test':list(),'cv':list()}\n",
    "\n",
    "#misClassifications\n",
    "print(\"--> Train MisClassification\")\n",
    "TRpredicted_svm = text_clf_svm.predict(X_train)\n",
    "misClTr_svm=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_train,TRpredicted_svm,rownames=[\"True\"],colnames=[\"Train_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TRpredicted_svm)):\n",
    "    if TRpredicted_svm[i]!=Y_train.iloc[i]:\n",
    "        print(\"X_Train.values[\",i,\"] Predicted\",TRpredicted_svm[i],\"Actual\",Y_train.iloc[i],\n",
    "              \"File:[errI=\"+str(X_train.index[i]),newfiles[X_train.index[i]],\"]\")\n",
    "        misClTr_svm.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['train'].append(newfiles[X_train.index[i]])\n",
    "print(len(misClTr_svm),\" misses in TrainData\")\n",
    "\n",
    "print(\"--> Test MisClassification\")\n",
    "TSpredicted_svm = text_clf_svm.predict(X_test)\n",
    "misClTs_svm=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_test,TSpredicted_svm,rownames=[\"True\"],colnames=[\"Test_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TSpredicted_svm)):\n",
    "    if TSpredicted_svm[i]!=Y_test.iloc[i]:\n",
    "        print(\"X_test.values[\",i,\"] Predicted\",TSpredicted_svm[i],\"Actual\",Y_test.iloc[i],\n",
    "              \"File:[errI=\"+str(X_test.index[i]),newfiles[X_test.index[i]],\"]\")\n",
    "        misClTs_svm.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['test'].append(newfiles[X_test.index[i]])\n",
    "\n",
    "print(len(misClTs_svm),\" misses in TestData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#study misclassified doc errI [by filename or errI_index]\n",
    "#errI=newfiles.index('BUY/Gallego.pdf.txt')\n",
    "errI=0\n",
    "#print(errI,\"TESTdata\" if errI in X_test else \"TRAINdata\",newfiles[errI],X_test.get(errI,0) or X_train.get(errI,0))\n",
    "#os.system(\"np++ \"+newfiles[errI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Accuracy\n",
      "TRAIN 1.0\n",
      "TEST 0.8436018957345972\n",
      "--> Train MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  misses in TrainData\n",
      "--> Test MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "      <td>80</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.values[ 5 ] Predicted EPG Actual ADD File:[errI=260 ADD/18-010.pdf.txt ]\n",
      "X_test.values[ 19 ] Predicted EPG Actual BUY File:[errI=353 BUY/NCS678.docx.txt ]\n",
      "X_test.values[ 31 ] Predicted ADD Actual EPG File:[errI=587 EPG/45752.pdf.txt ]\n",
      "X_test.values[ 34 ] Predicted EPG Actual ADD File:[errI=231 ADD/17-202.pdf.txt ]\n",
      "X_test.values[ 38 ] Predicted EPG Actual ADD File:[errI=88 ADD/17-053.pdf.txt ]\n",
      "X_test.values[ 45 ] Predicted BUY Actual EPG File:[errI=692 EPG/45868.pdf.txt ]\n",
      "X_test.values[ 54 ] Predicted EPG Actual ADD File:[errI=31 ADD/17 092.pdf.txt ]\n",
      "X_test.values[ 60 ] Predicted EPG Actual ADD File:[errI=174 ADD/17-145.pdf.txt ]\n",
      "X_test.values[ 64 ] Predicted ADD Actual EPG File:[errI=687 EPG/45863.pdf.txt ]\n",
      "X_test.values[ 78 ] Predicted EPG Actual ADD File:[errI=234 ADD/17-205.pdf.txt ]\n",
      "X_test.values[ 81 ] Predicted EPG Actual BUY File:[errI=381 BUY/RIS456.docx.txt ]\n",
      "X_test.values[ 91 ] Predicted ADD Actual EPG File:[errI=485 EPG/45,941.pdf.txt ]\n",
      "X_test.values[ 102 ] Predicted ADD Actual EPG File:[errI=430 EPG/45,884.pdf.txt ]\n",
      "X_test.values[ 118 ] Predicted EPG Actual BUY File:[errI=349 BUY/MossFirstPremier.pdf.txt ]\n",
      "X_test.values[ 125 ] Predicted EPG Actual ADD File:[errI=2 ADD/16173.pdf.txt ]\n",
      "X_test.values[ 127 ] Predicted EPG Actual BUY File:[errI=319 BUY/GraySeterus.pdf.txt ]\n",
      "X_test.values[ 140 ] Predicted ADD Actual EPG File:[errI=639 EPG/45814.pdf.txt ]\n",
      "X_test.values[ 141 ] Predicted ADD Actual EPG File:[errI=545 EPG/45710.pdf.txt ]\n",
      "X_test.values[ 143 ] Predicted EPG Actual BUY File:[errI=367 BUY/PedigoRobertson.pdf.txt ]\n",
      "X_test.values[ 150 ] Predicted ADD Actual EPG File:[errI=589 EPG/45754.pdf.txt ]\n",
      "X_test.values[ 151 ] Predicted EPG Actual ADD File:[errI=208 ADD/17-179.pdf.txt ]\n",
      "X_test.values[ 155 ] Predicted EPG Actual BUY File:[errI=377 BUY/RIH575.docx.txt ]\n",
      "X_test.values[ 162 ] Predicted EPG Actual ADD File:[errI=60 ADD/17-025.pdf.txt ]\n",
      "X_test.values[ 163 ] Predicted BUY Actual ADD File:[errI=213 ADD/17-184.pdf.txt ]\n",
      "X_test.values[ 166 ] Predicted EPG Actual ADD File:[errI=181 ADD/17-152.pdf.txt ]\n",
      "X_test.values[ 167 ] Predicted ADD Actual EPG File:[errI=525 EPG/45246.pdf.txt ]\n",
      "X_test.values[ 168 ] Predicted EPG Actual ADD File:[errI=239 ADD/17-210.pdf.txt ]\n",
      "X_test.values[ 174 ] Predicted ADD Actual EPG File:[errI=428 EPG/45,882.pdf.txt ]\n",
      "X_test.values[ 190 ] Predicted EPG Actual ADD File:[errI=7 ADD/16178.pdf.txt ]\n",
      "X_test.values[ 194 ] Predicted ADD Actual BUY File:[errI=265 BUY/AdamsPenn.pdf.txt ]\n",
      "X_test.values[ 196 ] Predicted ADD Actual EPG File:[errI=590 EPG/45755.pdf.txt ]\n",
      "X_test.values[ 197 ] Predicted EPG Actual BUY File:[errI=328 BUY/INH1456.doc.txt ]\n",
      "X_test.values[ 204 ] Predicted ADD Actual EPG File:[errI=567 EPG/45732.pdf.txt ]\n",
      "33  misses in TestData\n"
     ]
    }
   ],
   "source": [
    "#pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "algoname='dt'\n",
    "#DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "text_clf_dt = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3), )),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf',DecisionTreeClassifier(\n",
    "                         criterion='gini', splitter='best', max_depth=None, \n",
    "                         min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                         max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                         min_impurity_split=None, class_weight=None, presort=False))\n",
    "                    ])\n",
    "\n",
    "clfname='text_clf_'+algoname\n",
    "StorParam['hparams'][algoname]={x:globals()[clfname].named_steps[x].get_params() for x in globals()[clfname].named_steps.keys()}\n",
    "#fit_transforms of data to pipeline\n",
    "fit_dt=text_clf_dt.fit(X_train,Y_train)\n",
    "\n",
    "#testing model\n",
    "trscr=text_clf_dt.score(X_train,Y_train)\n",
    "tsscr=text_clf_dt.score(X_test,Y_test)\n",
    "print(\"--> Accuracy\")\n",
    "print(\"TRAIN\",trscr)\n",
    "print(\"TEST\",tsscr)\n",
    "StorParam['metrics'][algoname]={'train':trscr,'test':tsscr,'cv':None}\n",
    "StorParam['filesMisClf'][algoname]={'train':list(),'test':list(),'cv':list()}\n",
    "\n",
    "#misClassifications\n",
    "print(\"--> Train MisClassification\")\n",
    "TRpredicted_dt = text_clf_dt.predict(X_train)\n",
    "misClTr_dt=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_train,TRpredicted_dt,rownames=[\"True\"],colnames=[\"Train_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TRpredicted_dt)):\n",
    "    if TRpredicted_dt[i]!=Y_train.iloc[i]:\n",
    "        print(\"X_Train.values[\",i,\"] Predicted\",TRpredicted_dt[i],\"Actual\",Y_train.iloc[i],\n",
    "              \"File:[errI=\"+str(X_train.index[i]),newfiles[X_train.index[i]],\"]\")\n",
    "        misClTr_dt.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['train'].append(newfiles[X_train.index[i]])\n",
    "\n",
    "print(len(misClTr_dt),\" misses in TrainData\")\n",
    "\n",
    "print(\"--> Test MisClassification\")\n",
    "TSpredicted_dt = text_clf_dt.predict(X_test)\n",
    "misClTs_dt=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_test,TSpredicted_dt,rownames=[\"True\"],colnames=[\"Test_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TSpredicted_dt)):\n",
    "    if TSpredicted_dt[i]!=Y_test.iloc[i]:\n",
    "        print(\"X_test.values[\",i,\"] Predicted\",TSpredicted_dt[i],\"Actual\",Y_test.iloc[i],\n",
    "              \"File:[errI=\"+str(X_test.index[i]),newfiles[X_test.index[i]],\"]\")\n",
    "        misClTs_dt.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['test'].append(newfiles[X_test.index[i]])\n",
    "\n",
    "print(len(misClTs_dt),\" misses in TestData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#study misclassified doc errI [by filename or errI_index]\n",
    "#errI=newfiles.index('MC-275/0001553350-17-000313-4.txt')\n",
    "errI=121\n",
    "#print(errI,\"TESTdata\" if errI in X_test else \"TRAINdata\",newfiles[errI],X_test.get(errI,0) or X_train.get(errI,0))\n",
    "#os.system(\"np++ \"+newfiles[errI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Standard Grad. Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Accuracy\n",
      "TRAIN 1.0\n",
      "TEST 0.9289099526066351\n",
      "--> Train MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  misses in TrainData\n",
      "--> Test MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>90</td>\n",
       "      <td>43</td>\n",
       "      <td>78</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.values[ 13 ] Predicted EPG Actual ADD File:[errI=149 ADD/17-120.pdf.txt ]\n",
      "X_test.values[ 31 ] Predicted ADD Actual EPG File:[errI=587 EPG/45752.pdf.txt ]\n",
      "X_test.values[ 37 ] Predicted EPG Actual BUY File:[errI=382 BUY/RocheleauElder.pdf.txt ]\n",
      "X_test.values[ 45 ] Predicted ADD Actual EPG File:[errI=692 EPG/45868.pdf.txt ]\n",
      "X_test.values[ 46 ] Predicted EPG Actual ADD File:[errI=179 ADD/17-150.pdf.txt ]\n",
      "X_test.values[ 58 ] Predicted EPG Actual BUY File:[errI=284 BUY/BuenoLR.pdf.txt ]\n",
      "X_test.values[ 67 ] Predicted EPG Actual ADD File:[errI=78 ADD/17-043.pdf.txt ]\n",
      "X_test.values[ 95 ] Predicted EPG Actual ADD File:[errI=163 ADD/17-134.pdf.txt ]\n",
      "X_test.values[ 127 ] Predicted EPG Actual BUY File:[errI=319 BUY/GraySeterus.pdf.txt ]\n",
      "X_test.values[ 134 ] Predicted EPG Actual BUY File:[errI=344 BUY/McMahonLVNV.pdf.txt ]\n",
      "X_test.values[ 143 ] Predicted EPG Actual BUY File:[errI=367 BUY/PedigoRobertson.pdf.txt ]\n",
      "X_test.values[ 174 ] Predicted ADD Actual EPG File:[errI=428 EPG/45,882.pdf.txt ]\n",
      "X_test.values[ 195 ] Predicted EPG Actual BUY File:[errI=411 BUY/WVCode.mht.txt ]\n",
      "X_test.values[ 196 ] Predicted ADD Actual EPG File:[errI=590 EPG/45755.pdf.txt ]\n",
      "X_test.values[ 204 ] Predicted ADD Actual EPG File:[errI=567 EPG/45732.pdf.txt ]\n",
      "15  misses in TestData\n"
     ]
    }
   ],
   "source": [
    "#pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "algoname='sgd'\n",
    "#sgd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_sgd = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3), )),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf',SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None))\n",
    "                    ])\n",
    "\n",
    "clfname='text_clf_'+algoname\n",
    "StorParam['hparams'][algoname]={x:globals()[clfname].named_steps[x].get_params() for x in globals()[clfname].named_steps.keys()}\n",
    "#fit_transforms of data to pipeline\n",
    "fit_sgd=text_clf_sgd.fit(X_train,Y_train)\n",
    "\n",
    "#testing model\n",
    "trscr=text_clf_sgd.score(X_train,Y_train)\n",
    "tsscr=text_clf_sgd.score(X_test,Y_test)\n",
    "print(\"--> Accuracy\")\n",
    "print(\"TRAIN\",trscr)\n",
    "print(\"TEST\",tsscr)\n",
    "StorParam['metrics'][algoname]={'train':trscr,'test':tsscr,'cv':None}\n",
    "StorParam['filesMisClf'][algoname]={'train':list(),'test':list(),'cv':list()}\n",
    "\n",
    "#misClassifications\n",
    "print(\"--> Train MisClassification\")\n",
    "TRpredicted_sgd = text_clf_sgd.predict(X_train)\n",
    "misClTr_sgd=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_train,TRpredicted_sgd,rownames=[\"True\"],colnames=[\"Train_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TRpredicted_sgd)):\n",
    "    if TRpredicted_sgd[i]!=Y_train.iloc[i]:\n",
    "        print(\"X_Train.values[\",i,\"] Predicted\",TRpredicted_sgd[i],\"Actual\",Y_train.iloc[i],\n",
    "              \"File:[errI=\"+str(X_train.index[i]),newfiles[X_train.index[i]],\"]\")\n",
    "        misClTr_sgd.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['train'].append(newfiles[X_train.index[i]])\n",
    "\n",
    "print(len(misClTr_sgd),\" misses in TrainData\")\n",
    "\n",
    "print(\"--> Test MisClassification\")\n",
    "TSpredicted_sgd = text_clf_sgd.predict(X_test)\n",
    "misClTs_sgd=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_test,TSpredicted_sgd,rownames=[\"True\"],colnames=[\"Test_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(TSpredicted_sgd)):\n",
    "    if TSpredicted_sgd[i]!=Y_test.iloc[i]:\n",
    "        print(\"X_test.values[\",i,\"] Predicted\",TSpredicted_sgd[i],\"Actual\",Y_test.iloc[i],\n",
    "              \"File:[errI=\"+str(X_test.index[i]),newfiles[X_test.index[i]],\"]\")\n",
    "        misClTs_sgd.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['test'].append(newfiles[X_test.index[i]])\n",
    "\n",
    "print(len(misClTs_sgd),\" misses in TestData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#study misclassified doc errI [by filename or errI_index]\n",
    "#errI=newfiles.index('Others-275/new 206.txt')\n",
    "errI=121\n",
    "#print(errI,\"TESTdata\" if errI in X_test else \"TRAINdata\",newfiles[errI],X_test.get(errI,0) or X_train.get(errI,0))\n",
    "#os.system(\"np++ \"+newfiles[errI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossValidation\n",
    "Beware: this notebook has opposite meaning of Test and CrossVal\n",
    "\n",
    "And thats not cool. but meh, im lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> NAIVE BAYES CrossVal MisClassification\n",
      "TEST nb 0.9084507042253521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CrVal_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>66</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cv.values[ 1 ] Predicted EPG Actual ADD File:[errI=18 ADD/16189.pdf.txt ]\n",
      "X_cv.values[ 21 ] Predicted EPG Actual ADD File:[errI=131 ADD/17-101.pdf.txt ]\n",
      "X_cv.values[ 24 ] Predicted EPG Actual BUY File:[errI=320 BUY/Hageman.pdf.txt ]\n",
      "X_cv.values[ 25 ] Predicted EPG Actual ADD File:[errI=141 ADD/17-111.pdf.txt ]\n",
      "X_cv.values[ 50 ] Predicted ADD Actual BUY File:[errI=375 BUY/RielNavient.pdf.txt ]\n",
      "X_cv.values[ 58 ] Predicted EPG Actual ADD File:[errI=257 ADD/18-007.pdf.txt ]\n",
      "X_cv.values[ 62 ] Predicted EPG Actual BUY File:[errI=321 BUY/HamburgerNorth.pdf.txt ]\n",
      "X_cv.values[ 73 ] Predicted EPG Actual BUY File:[errI=324 BUY/HudsonCiti.pdf.txt ]\n",
      "X_cv.values[ 97 ] Predicted EPG Actual ADD File:[errI=142 ADD/17-112.pdf.txt ]\n",
      "X_cv.values[ 105 ] Predicted EPG Actual BUY File:[errI=289 BUY/CFPBGordon.pdf.txt ]\n",
      "X_cv.values[ 119 ] Predicted EPG Actual BUY File:[errI=296 BUY/DennisReizman.pdf.txt ]\n",
      "X_cv.values[ 131 ] Predicted EPG Actual BUY File:[errI=363 BUY/ORS 205_460 - Order to show cause why invalid claim of encumbrance should not be stricken - 2013 Oregon Revised Statutes.mht.txt ]\n",
      "X_cv.values[ 133 ] Predicted EPG Actual BUY File:[errI=310 BUY/Gallego.pdf.txt ]\n",
      "13  misses in CrossValData\n"
     ]
    }
   ],
   "source": [
    "print(\"--> NAIVE BAYES CrossVal MisClassification\")\n",
    "algoname='nb'\n",
    "cvscr=text_clf_nb.score(X_cv,Y_cv)\n",
    "print(\"TEST\",algoname,cvscr)\n",
    "StorParam['metrics'][algoname]['cv']=cvscr\n",
    "CVpredicted_nb = text_clf_nb.predict(X_cv)\n",
    "misClcv_nb=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_cv,CVpredicted_nb,rownames=[\"True\"],colnames=[\"CrVal_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(CVpredicted_nb)):\n",
    "    if CVpredicted_nb[i]!=Y_cv.iloc[i]:\n",
    "        print(\"X_cv.values[\",i,\"] Predicted\",CVpredicted_nb[i],\"Actual\",Y_cv.iloc[i],\n",
    "              \"File:[errI=\"+str(X_cv.index[i]),newfiles[X_cv.index[i]],\"]\")\n",
    "        misClcv_nb.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['cv'].append(newfiles[X_cv.index[i]])\n",
    "print(len(misClcv_nb),\" misses in CrossValData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> SVM CrossVal MisClassification\n",
      "TEST svm 0.9225352112676056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CrVal_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>63</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cv.values[ 1 ] Predicted EPG Actual ADD File:[errI=18 ADD/16189.pdf.txt ]\n",
      "X_cv.values[ 2 ] Predicted EPG Actual ADD File:[errI=65 ADD/17-030.pdf.txt ]\n",
      "X_cv.values[ 21 ] Predicted EPG Actual ADD File:[errI=131 ADD/17-101.pdf.txt ]\n",
      "X_cv.values[ 25 ] Predicted EPG Actual ADD File:[errI=141 ADD/17-111.pdf.txt ]\n",
      "X_cv.values[ 58 ] Predicted EPG Actual ADD File:[errI=257 ADD/18-007.pdf.txt ]\n",
      "X_cv.values[ 62 ] Predicted EPG Actual BUY File:[errI=321 BUY/HamburgerNorth.pdf.txt ]\n",
      "X_cv.values[ 97 ] Predicted EPG Actual ADD File:[errI=142 ADD/17-112.pdf.txt ]\n",
      "X_cv.values[ 105 ] Predicted EPG Actual BUY File:[errI=289 BUY/CFPBGordon.pdf.txt ]\n",
      "X_cv.values[ 115 ] Predicted ADD Actual EPG File:[errI=551 EPG/45716.pdf.txt ]\n",
      "X_cv.values[ 119 ] Predicted EPG Actual BUY File:[errI=296 BUY/DennisReizman.pdf.txt ]\n",
      "X_cv.values[ 131 ] Predicted EPG Actual BUY File:[errI=363 BUY/ORS 205_460 - Order to show cause why invalid claim of encumbrance should not be stricken - 2013 Oregon Revised Statutes.mht.txt ]\n",
      "11  misses in CrossValData\n"
     ]
    }
   ],
   "source": [
    "print(\"--> SVM CrossVal MisClassification\")\n",
    "algoname='svm'\n",
    "cvscr=text_clf_svm.score(X_cv,Y_cv)\n",
    "print(\"TEST\",algoname,cvscr)\n",
    "StorParam['metrics'][algoname]['cv']=cvscr\n",
    "CVpredicted_svm = text_clf_svm.predict(X_cv)\n",
    "misClcv_svm=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_cv,CVpredicted_svm,rownames=[\"True\"],colnames=[\"CrVal_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(CVpredicted_svm)):\n",
    "    if CVpredicted_svm[i]!=Y_cv.iloc[i]:\n",
    "        print(\"X_cv.values[\",i,\"] Predicted\",CVpredicted_svm[i],\"Actual\",Y_cv.iloc[i],\n",
    "              \"File:[errI=\"+str(X_cv.index[i]),newfiles[X_cv.index[i]],\"]\")\n",
    "        misClcv_svm.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['cv'].append(newfiles[X_cv.index[i]])\n",
    "print(len(misClcv_svm),\" misses in CrossValData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> DecisionTree CrossVal MisClassification\n",
      "TEST dt 0.8309859154929577\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CrVal_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cv.values[ 1 ] Predicted EPG Actual ADD File:[errI=18 ADD/16189.pdf.txt ]\n",
      "X_cv.values[ 2 ] Predicted EPG Actual ADD File:[errI=65 ADD/17-030.pdf.txt ]\n",
      "X_cv.values[ 8 ] Predicted EPG Actual ADD File:[errI=70 ADD/17-035.pdf.txt ]\n",
      "X_cv.values[ 15 ] Predicted EPG Actual BUY File:[errI=342 BUY/McGillCiti.PDF.txt ]\n",
      "X_cv.values[ 19 ] Predicted ADD Actual EPG File:[errI=701 EPG/MarshallRawlings042017.pdf.txt ]\n",
      "X_cv.values[ 21 ] Predicted EPG Actual ADD File:[errI=131 ADD/17-101.pdf.txt ]\n",
      "X_cv.values[ 23 ] Predicted ADD Actual EPG File:[errI=683 EPG/45858.pdf.txt ]\n",
      "X_cv.values[ 36 ] Predicted BUY Actual EPG File:[errI=497 EPG/45,953.pdf.txt ]\n",
      "X_cv.values[ 37 ] Predicted ADD Actual EPG File:[errI=429 EPG/45,883.pdf.txt ]\n",
      "X_cv.values[ 43 ] Predicted EPG Actual BUY File:[errI=275 BUY/BenzemannCiti.pdf.txt ]\n",
      "X_cv.values[ 56 ] Predicted ADD Actual EPG File:[errI=482 EPG/45,938.pdf.txt ]\n",
      "X_cv.values[ 70 ] Predicted EPG Actual ADD File:[errI=110 ADD/17-075.pdf.txt ]\n",
      "X_cv.values[ 72 ] Predicted ADD Actual EPG File:[errI=495 EPG/45,951.pdf.txt ]\n",
      "X_cv.values[ 76 ] Predicted ADD Actual EPG File:[errI=672 EPG/45847.pdf.txt ]\n",
      "X_cv.values[ 81 ] Predicted EPG Actual BUY File:[errI=272 BUY/Avila.pdf.txt ]\n",
      "X_cv.values[ 85 ] Predicted EPG Actual ADD File:[errI=124 ADD/17-089.pdf.txt ]\n",
      "X_cv.values[ 87 ] Predicted ADD Actual EPG File:[errI=527 EPG/45248.pdf.txt ]\n",
      "X_cv.values[ 112 ] Predicted EPG Actual ADD File:[errI=100 ADD/17-065.pdf.txt ]\n",
      "X_cv.values[ 114 ] Predicted BUY Actual EPG File:[errI=626 EPG/45801..pdf.txt ]\n",
      "X_cv.values[ 116 ] Predicted ADD Actual EPG File:[errI=660 EPG/45835.pdf.txt ]\n",
      "X_cv.values[ 125 ] Predicted EPG Actual ADD File:[errI=84 ADD/17-049.pdf.txt ]\n",
      "X_cv.values[ 127 ] Predicted EPG Actual BUY File:[errI=393 BUY/TalaieWells.pdf.txt ]\n",
      "X_cv.values[ 136 ] Predicted EPG Actual ADD File:[errI=9 ADD/16180.pdf.txt ]\n",
      "X_cv.values[ 137 ] Predicted EPG Actual ADD File:[errI=81 ADD/17-046.pdf.txt ]\n",
      "24  misses in CrossValData\n"
     ]
    }
   ],
   "source": [
    "print(\"--> DecisionTree CrossVal MisClassification\")\n",
    "algoname='dt'\n",
    "cvscr=text_clf_dt.score(X_cv,Y_cv)\n",
    "print(\"TEST\",algoname,cvscr)\n",
    "StorParam['metrics'][algoname]['cv']=cvscr\n",
    "CVpredicted_dt = text_clf_dt.predict(X_cv)\n",
    "misClcv_dt=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_cv,CVpredicted_dt,rownames=[\"True\"],colnames=[\"CrVal_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(CVpredicted_dt)):\n",
    "    if CVpredicted_dt[i]!=Y_cv.iloc[i]:\n",
    "        print(\"X_cv.values[\",i,\"] Predicted\",CVpredicted_dt[i],\"Actual\",Y_cv.iloc[i],\n",
    "              \"File:[errI=\"+str(X_cv.index[i]),newfiles[X_cv.index[i]],\"]\")\n",
    "        misClcv_dt.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['cv'].append(newfiles[X_cv.index[i]])\n",
    "print(len(misClcv_dt),\" misses in CrossValData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> LinearStandardGradientDescent CrossVal MisClassification\n",
      "TEST sgd 0.9154929577464789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CrVal_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cv.values[ 1 ] Predicted EPG Actual ADD File:[errI=18 ADD/16189.pdf.txt ]\n",
      "X_cv.values[ 2 ] Predicted EPG Actual ADD File:[errI=65 ADD/17-030.pdf.txt ]\n",
      "X_cv.values[ 21 ] Predicted EPG Actual ADD File:[errI=131 ADD/17-101.pdf.txt ]\n",
      "X_cv.values[ 25 ] Predicted EPG Actual ADD File:[errI=141 ADD/17-111.pdf.txt ]\n",
      "X_cv.values[ 58 ] Predicted EPG Actual ADD File:[errI=257 ADD/18-007.pdf.txt ]\n",
      "X_cv.values[ 62 ] Predicted EPG Actual BUY File:[errI=321 BUY/HamburgerNorth.pdf.txt ]\n",
      "X_cv.values[ 97 ] Predicted EPG Actual ADD File:[errI=142 ADD/17-112.pdf.txt ]\n",
      "X_cv.values[ 105 ] Predicted EPG Actual BUY File:[errI=289 BUY/CFPBGordon.pdf.txt ]\n",
      "X_cv.values[ 115 ] Predicted ADD Actual EPG File:[errI=551 EPG/45716.pdf.txt ]\n",
      "X_cv.values[ 119 ] Predicted EPG Actual BUY File:[errI=296 BUY/DennisReizman.pdf.txt ]\n",
      "X_cv.values[ 131 ] Predicted EPG Actual BUY File:[errI=363 BUY/ORS 205_460 - Order to show cause why invalid claim of encumbrance should not be stricken - 2013 Oregon Revised Statutes.mht.txt ]\n",
      "X_cv.values[ 136 ] Predicted EPG Actual ADD File:[errI=9 ADD/16180.pdf.txt ]\n",
      "12  misses in CrossValData\n"
     ]
    }
   ],
   "source": [
    "print(\"--> LinearStandardGradientDescent CrossVal MisClassification\")\n",
    "algoname='sgd'\n",
    "cvscr=text_clf_sgd.score(X_cv,Y_cv)\n",
    "print(\"TEST\",algoname,cvscr)\n",
    "StorParam['metrics'][algoname]['cv']=cvscr\n",
    "CVpredicted_sgd = text_clf_sgd.predict(X_cv)\n",
    "misClcv_sgd=list()\n",
    "#sklearn.metrics.confusion_matrix\n",
    "display(HTML(pd.crosstab(Y_cv,CVpredicted_sgd,rownames=[\"True\"],colnames=[\"CrVal_Predicted\"],margins=True).to_html()))\n",
    "for i in range(len(CVpredicted_sgd)):\n",
    "    if CVpredicted_sgd[i]!=Y_cv.iloc[i]:\n",
    "        print(\"X_cv.values[\",i,\"] Predicted\",CVpredicted_sgd[i],\"Actual\",Y_cv.iloc[i],\n",
    "              \"File:[errI=\"+str(X_cv.index[i]),newfiles[X_cv.index[i]],\"]\")\n",
    "        misClcv_sgd.append(i)\n",
    "        StorParam['filesMisClf'][algoname]['cv'].append(newfiles[X_cv.index[i]])\n",
    "print(len(misClcv_sgd),\" misses in CrossValData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "#### Analysing StorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hparams', 'metrics', 'filesMisClf', 'files', 'newfiles', 'preproc_comment', 'catg_val_count', 'SplitRatio_ts', 'SplitRatio_cv', 'Random_ts', 'Random_cv'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StorParam.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': {'cv': 0.8309859154929577, 'test': 0.8436018957345972, 'train': 1.0},\n",
       " 'nb': {'cv': 0.9084507042253521, 'test': 0.8957345971563981, 'train': 1.0},\n",
       " 'sgd': {'cv': 0.9154929577464789, 'test': 0.9289099526066351, 'train': 1.0},\n",
       " 'svm': {'cv': 0.9225352112676056, 'test': 0.933649289099526, 'train': 1.0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StorParam['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADD/16189.pdf.txt                                                                                                                       4\n",
       "EPG/45,882.pdf.txt                                                                                                                      4\n",
       "EPG/45752.pdf.txt                                                                                                                       4\n",
       "EPG/45868.pdf.txt                                                                                                                       4\n",
       "ADD/17-101.pdf.txt                                                                                                                      4\n",
       "BUY/GraySeterus.pdf.txt                                                                                                                 4\n",
       "EPG/45732.pdf.txt                                                                                                                       4\n",
       "ADD/17-112.pdf.txt                                                                                                                      3\n",
       "BUY/RocheleauElder.pdf.txt                                                                                                              3\n",
       "BUY/HamburgerNorth.pdf.txt                                                                                                              3\n",
       "ADD/17-150.pdf.txt                                                                                                                      3\n",
       "ADD/17-120.pdf.txt                                                                                                                      3\n",
       "ADD/18-007.pdf.txt                                                                                                                      3\n",
       "BUY/CFPBGordon.pdf.txt                                                                                                                  3\n",
       "BUY/DennisReizman.pdf.txt                                                                                                               3\n",
       "ADD/17-134.pdf.txt                                                                                                                      3\n",
       "BUY/BuenoLR.pdf.txt                                                                                                                     3\n",
       "ADD/17-111.pdf.txt                                                                                                                      3\n",
       "ADD/17-030.pdf.txt                                                                                                                      3\n",
       "BUY/ORS 205_460 - Order to show cause why invalid claim of encumbrance should not be stricken - 2013 Oregon Revised Statutes.mht.txt    3\n",
       "BUY/McMahonLVNV.pdf.txt                                                                                                                 3\n",
       "BUY/PedigoRobertson.pdf.txt                                                                                                             3\n",
       "ADD/17-043.pdf.txt                                                                                                                      2\n",
       "BUY/MossFirstPremier.pdf.txt                                                                                                            2\n",
       "EPG/45755.pdf.txt                                                                                                                       2\n",
       "EPG/45716.pdf.txt                                                                                                                       2\n",
       "BUY/WVCode.mht.txt                                                                                                                      2\n",
       "ADD/16180.pdf.txt                                                                                                                       2\n",
       "EPG/45830.pdf.txt                                                                                                                       1\n",
       "EPG/45849.pdf.txt                                                                                                                       1\n",
       "                                                                                                                                       ..\n",
       "BUY/INH1456.doc.txt                                                                                                                     1\n",
       "EPG/MarshallRawlings042017.pdf.txt                                                                                                      1\n",
       "EPG/45246.pdf.txt                                                                                                                       1\n",
       "BUY/MaddenMidland.pdf.txt                                                                                                               1\n",
       "BUY/AdamsPenn.pdf.txt                                                                                                                   1\n",
       "ADD/17-202.pdf.txt                                                                                                                      1\n",
       "EPG/45814.pdf.txt                                                                                                                       1\n",
       "EPG/45,953.pdf.txt                                                                                                                      1\n",
       "EPG/45847.pdf.txt                                                                                                                       1\n",
       "EPG/45,941.pdf.txt                                                                                                                      1\n",
       "EPG/45,883.pdf.txt                                                                                                                      1\n",
       "ADD/17-035.pdf.txt                                                                                                                      1\n",
       "EPG/45710.pdf.txt                                                                                                                       1\n",
       "ADD/17-038.pdf.txt                                                                                                                      1\n",
       "ADD/17-103.pdf.txt                                                                                                                      1\n",
       "ADD/17-205.pdf.txt                                                                                                                      1\n",
       "EPG/45,937.pdf.txt                                                                                                                      1\n",
       "EPG/45835.pdf.txt                                                                                                                       1\n",
       "BUY/TalaieWells.pdf.txt                                                                                                                 1\n",
       "EPG/45801..pdf.txt                                                                                                                      1\n",
       "EPG/45,884.pdf.txt                                                                                                                      1\n",
       "ADD/17-049.pdf.txt                                                                                                                      1\n",
       "EPG/45754.pdf.txt                                                                                                                       1\n",
       "ADD/18-010.pdf.txt                                                                                                                      1\n",
       "ADD/17-179.pdf.txt                                                                                                                      1\n",
       "ADD/17-075.pdf.txt                                                                                                                      1\n",
       "BUY/Gallego.pdf.txt                                                                                                                     1\n",
       "ADD/17 092.pdf.txt                                                                                                                      1\n",
       "EPG/45863.pdf.txt                                                                                                                       1\n",
       "ADD/17-145.pdf.txt                                                                                                                      1\n",
       "Length: 87, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MisClassifiedFiles_alongwith_NumberOfTimeMisClassified\n",
    "pd.Series(sum([sum(list(I.values()),[]) for I in StorParam['filesMisClf'].values()],[])).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rsTr=text_clf_nb.predict_proba(X_train)\n",
    "rs=text_clf_nb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999884853356"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=1\n",
    "trs=(sum([(max(x))**p for x in rsTr])/len(rsTr))**(1/p)\n",
    "\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADD' 'BUY' 'EPG']\n",
      "13 chale [1.02993687e-02 2.37242605e-06 9.89698259e-01] pr far from true= 0.979398890155869\n",
      "37 chale [3.26824980e-03 1.44337302e-04 9.96587413e-01] pr far from true= 0.9964430755996854\n",
      "45 chale [0.92023571 0.00141035 0.07835395] pr far from true= 0.8418817622368489\n",
      "46 chale [1.61757595e-03 1.38619304e-09 9.98382423e-01] pr far from true= 0.9967648467147093\n",
      "58 chale [0.01828005 0.00954766 0.97217228] pr far from true= 0.9626246181351056\n",
      "59 chale [2.60547518e-01 8.64564117e-15 7.39452482e-01] pr far from true= 0.4789049630853823\n",
      "67 chale [3.88477651e-02 1.87371605e-08 9.61152216e-01] pr far from true= 0.9223044511416798\n",
      "95 chale [3.50624770e-01 1.49692249e-08 6.49375215e-01] pr far from true= 0.2987504456482437\n",
      "96 chale [0.00341831 0.41479692 0.58178477] pr far from true= 0.16698784877795714\n",
      "101 chale [1.39553064e-01 5.22927386e-15 8.60446936e-01] pr far from true= 0.7208938728933804\n",
      "104 chale [6.64512149e-01 1.69205771e-08 3.35487834e-01] pr far from true= 0.32902431539254906\n",
      "107 chale [1.07302636e-01 4.49600613e-09 8.92697360e-01] pr far from true= 0.7853947244673462\n",
      "118 chale [5.68105927e-05 4.19064636e-01 5.80878554e-01] pr far from true= 0.16181391835470327\n",
      "119 chale [7.58338897e-01 5.62352154e-08 2.41661046e-01] pr far from true= 0.5166778511304214\n",
      "127 chale [3.50675130e-02 1.04013597e-04 9.64828473e-01] pr far from true= 0.9647244598481546\n",
      "128 chale [0.0014433  0.23600321 0.7625535 ] pr far from true= 0.5265502908283685\n",
      "134 chale [0.00680254 0.00203702 0.99116043] pr far from true= 0.9891234088248443\n",
      "143 chale [5.84412557e-05 4.80581942e-02 9.51883365e-01] pr far from true= 0.9038251703064666\n",
      "161 chale [6.38936475e-01 4.74818771e-11 3.61063525e-01] pr far from true= 0.27787294912977467\n",
      "174 chale [9.99999899e-01 1.00583599e-13 1.01477837e-07] pr far from true= 0.9999997970442166\n",
      "204 chale [9.97198616e-01 5.78718931e-11 2.80138423e-03] pr far from true= 0.9943972314779718\n",
      "31 Locha [1.00000000e+00 4.64265874e-18 2.84284463e-14] extra by 1.1514664444156608e-08 pr far from true=\n"
     ]
    }
   ],
   "source": [
    "print(text_clf_nb.classes_)\n",
    "for i in misClTs_nb:\n",
    "    if max(rs[i])<trs:#,\"less by\",-max(rs[i])+trs\n",
    "        print(i,\"chale\",rs[i],\"pr far from true=\",max(rs[i])-rs[i][text_clf_nb.classes_.tolist().index(Y_test.iloc[i])])\n",
    "for i in misClTs_nb:\n",
    "    if max(rs[i])>trs:\n",
    "        print(i,\"Locha\",rs[i],\"extra by\",max(rs[i])-trs,\"pr far from true=\",)\n",
    "#chale=>no catg has enough confidence on them\n",
    "#Locha=>wrong catg has confidence on them by <-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Â '==' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "NB tr \n",
      "        ADD       1.00      1.00      1.00       120\n",
      "        BUY       1.00      1.00      1.00        69\n",
      "        EPG       1.00      1.00      1.00       164\n",
      "\n",
      "avg / total       1.00      1.00      1.00       353\n",
      "\n",
      "NB ts \n",
      "        ADD       0.92      0.92      0.92        89\n",
      "        BUY       1.00      0.84      0.91        49\n",
      "        EPG       0.81      0.90      0.86        73\n",
      "\n",
      "avg / total       0.90      0.90      0.90       211\n",
      "\n",
      "NB cv \n",
      "        ADD       0.98      0.90      0.94        52\n",
      "        BUY       1.00      0.78      0.88        36\n",
      "        EPG       0.82      1.00      0.90        54\n",
      "\n",
      "avg / total       0.92      0.91      0.91       142\n",
      "\n",
      "SVM tr \n",
      "        ADD       1.00      1.00      1.00       120\n",
      "        BUY       1.00      1.00      1.00        69\n",
      "        EPG       1.00      1.00      1.00       164\n",
      "\n",
      "avg / total       1.00      1.00      1.00       353\n",
      "\n",
      "SVM ts \n",
      "        ADD       0.95      0.94      0.95        89\n",
      "        BUY       1.00      0.90      0.95        49\n",
      "        EPG       0.87      0.95      0.91        73\n",
      "\n",
      "avg / total       0.94      0.93      0.93       211\n",
      "\n",
      "SVM cv \n",
      "        ADD       0.98      0.88      0.93        52\n",
      "        BUY       1.00      0.89      0.94        36\n",
      "        EPG       0.84      0.98      0.91        54\n",
      "\n",
      "avg / total       0.93      0.92      0.92       142\n",
      "\n",
      "DT tr \n",
      "        ADD       1.00      1.00      1.00       120\n",
      "        BUY       1.00      1.00      1.00        69\n",
      "        EPG       1.00      1.00      1.00       164\n",
      "\n",
      "avg / total       1.00      1.00      1.00       353\n",
      "\n",
      "DT ts \n",
      "        ADD       0.86      0.85      0.86        89\n",
      "        BUY       0.95      0.84      0.89        49\n",
      "        EPG       0.76      0.84      0.80        73\n",
      "\n",
      "avg / total       0.85      0.84      0.85       211\n",
      "\n",
      "DT cv \n",
      "        ADD       0.84      0.81      0.82        52\n",
      "        BUY       0.94      0.89      0.91        36\n",
      "        EPG       0.76      0.81      0.79        54\n",
      "\n",
      "avg / total       0.83      0.83      0.83       142\n",
      "\n",
      "SGD tr \n",
      "        ADD       1.00      1.00      1.00       120\n",
      "        BUY       1.00      1.00      1.00        69\n",
      "        EPG       1.00      1.00      1.00       164\n",
      "\n",
      "avg / total       1.00      1.00      1.00       353\n",
      "\n",
      "SGD ts \n",
      "        ADD       0.94      0.96      0.95        89\n",
      "        BUY       1.00      0.88      0.93        49\n",
      "        EPG       0.87      0.93      0.90        73\n",
      "\n",
      "avg / total       0.93      0.93      0.93       211\n",
      "\n",
      "SGD cv \n",
      "        ADD       0.98      0.87      0.92        52\n",
      "        BUY       1.00      0.89      0.94        36\n",
      "        EPG       0.83      0.98      0.90        54\n",
      "\n",
      "avg / total       0.93      0.92      0.92       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('             precision    recall  f1-score   support')\n",
    "for al in \"nb svm dt sgd\".split():\n",
    "    for dsy,ds in {\"train\":\"TR\",\"test\":\"TS\",\"cv\":\"CV\"}.items():\n",
    "        print(al.upper(),ds.lower(),'\\n'.join(sklearn.metrics.classification_report(globals()[\"Y_\"+dsy],globals()[ds+\"predicted_\"+al]).split('\\n')[1:]))\n",
    "#print(\"svm_ts\",'\\n'.join(sklearn.metrics.classification_report(Y_test,TSpredicted_svm).split('\\n')[1:]))\n",
    "#print(\"dt_ts\",'\\n'.join(sklearn.metrics.classification_report(Y_test,TSpredicted_dt).split('\\n')[1:]))\n",
    "#print(\"sgd_ts\",'\\n'.join(sklearn.metrics.classification_report(Y_test,TSpredicted_sgd).split('\\n')[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        ...near_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitPipe(algoname,text_clf_):\n",
    "    global StorParam,X_train,X_test,Y_train,Y_test,X_cv,Y_cv\n",
    "    StorParam['hparams'][algoname]={x:text_clf_.named_steps[x].get_params() for x in text_clf_.named_steps.keys()}\n",
    "    #fit_transforms of data to pipeline\n",
    "    fit_=text_clf_.fit(X_train,Y_train)\n",
    "\n",
    "    #testing model\n",
    "    print(\"--> Accuracy\")\n",
    "    \n",
    "    TRpredicted_ = text_clf_.predict(X_train)\n",
    "    #trscr_=text_clf_.score(X_train,Y_train)\n",
    "    crtab_tr=pd.crosstab(Y_train,TRpredicted_,rownames=[\"True\"],colnames=[\"Train_Predicted\"],margins=True)\n",
    "    trscr_=1-(crtab_tr.All.All-sum([crtab_tr[c][c] for c in text_clf_.classes_]))/crtab_tr.All.All\n",
    "    print(\"TRAIN\",trscr_)\n",
    "\n",
    "    TSpredicted_ = text_clf_.predict(X_test)\n",
    "    #tsscr_=text_clf_.score(X_test,Y_test)\n",
    "    crtab_ts=pd.crosstab(Y_test,TSpredicted_,rownames=[\"True\"],colnames=[\"Test_Predicted\"],margins=True)\n",
    "    tsscr_=1-(crtab_ts.All.All-sum([crtab_ts[c][c] for c in text_clf_.classes_]))/crtab_ts.All.All\n",
    "    print(\"TEST\",tsscr_)\n",
    "    \n",
    "    StorParam['metrics'][algoname]={'train':trscr_,'test':tsscr_,'cv':None}\n",
    "    StorParam['filesMisClf'][algoname]={'train':list(),'test':list(),'cv':list()}\n",
    "\n",
    "    #misClassifications\n",
    "    print(\"--> Train MisClassification\")\n",
    "    misClTr_=list()\n",
    "    #sklearn.metrics.confusion_matrix\n",
    "    display(HTML(crtab_tr.to_html()))\n",
    "    for i in range(len(TRpredicted_)):\n",
    "        if TRpredicted_[i]!=Y_train.iloc[i]:\n",
    "            print(\"X_Train.values[\",i,\"] Predicted\",TRpredicted_[i],\"Actual\",Y_train.iloc[i],\n",
    "                  \"File:[errI=\"+str(X_train.index[i]),newfiles[X_train.index[i]],\"]\")\n",
    "            misClTr_.append(i)\n",
    "            StorParam['filesMisClf'][algoname]['train'].append(newfiles[X_train.index[i]])\n",
    "    print(len(misClTr_),\" misses in TrainData\")\n",
    "\n",
    "    print(\"--> Test MisClassification\")\n",
    "    misClTs_=list()\n",
    "    #sklearn.metrics.confusion_matrix\n",
    "    display(HTML(crtab_ts.to_html()))\n",
    "    for i in range(len(TSpredicted_)):\n",
    "        if TSpredicted_[i]!=Y_test.iloc[i]:\n",
    "            print(\"X_test.values[\",i,\"] Predicted\",TSpredicted_[i],\"Actual\",Y_test.iloc[i],\n",
    "                  \"File:[errI=\"+str(X_test.index[i]),newfiles[X_test.index[i]],\"]\")\n",
    "            misClTs_.append(i)\n",
    "            StorParam['filesMisClf'][algoname]['test'].append(newfiles[X_test.index[i]])\n",
    "\n",
    "    print(len(misClTs_),\" misses in TestData\")\n",
    "    \n",
    "    #push these vars to global namespace\n",
    "    returnD={k+algoname:v for k,v in locals().items() if k.endswith('_')}\n",
    "    for k,v in returnD.items():globals()[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Accuracy\n",
      "TRAIN 1.0\n",
      "TEST 0.933649289099526\n",
      "--> Train MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  misses in TrainData\n",
      "--> Test MisClassification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_Predicted</th>\n",
       "      <th>ADD</th>\n",
       "      <th>BUY</th>\n",
       "      <th>EPG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADD</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPG</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.values[ 13 ] Predicted EPG Actual ADD File:[errI=149 ADD/17-120.pdf.txt ]\n",
      "X_test.values[ 31 ] Predicted ADD Actual EPG File:[errI=587 EPG/45752.pdf.txt ]\n",
      "X_test.values[ 37 ] Predicted EPG Actual BUY File:[errI=382 BUY/RocheleauElder.pdf.txt ]\n",
      "X_test.values[ 45 ] Predicted ADD Actual EPG File:[errI=692 EPG/45868.pdf.txt ]\n",
      "X_test.values[ 46 ] Predicted EPG Actual ADD File:[errI=179 ADD/17-150.pdf.txt ]\n",
      "X_test.values[ 58 ] Predicted EPG Actual BUY File:[errI=284 BUY/BuenoLR.pdf.txt ]\n",
      "X_test.values[ 95 ] Predicted EPG Actual ADD File:[errI=163 ADD/17-134.pdf.txt ]\n",
      "X_test.values[ 127 ] Predicted EPG Actual BUY File:[errI=319 BUY/GraySeterus.pdf.txt ]\n",
      "X_test.values[ 134 ] Predicted EPG Actual BUY File:[errI=344 BUY/McMahonLVNV.pdf.txt ]\n",
      "X_test.values[ 152 ] Predicted EPG Actual ADD File:[errI=247 ADD/17-218.pdf.txt ]\n",
      "X_test.values[ 174 ] Predicted ADD Actual EPG File:[errI=428 EPG/45,882.pdf.txt ]\n",
      "X_test.values[ 178 ] Predicted EPG Actual ADD File:[errI=108 ADD/17-073.pdf.txt ]\n",
      "X_test.values[ 195 ] Predicted EPG Actual BUY File:[errI=411 BUY/WVCode.mht.txt ]\n",
      "X_test.values[ 204 ] Predicted ADD Actual EPG File:[errI=567 EPG/45732.pdf.txt ]\n",
      "14  misses in TestData\n"
     ]
    }
   ],
   "source": [
    "#pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "#svm_svc\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3), )),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC(decision_function_shape=\"ovo\", C = 1000000, kernel='rbf', gamma ='auto'))\n",
    "                    ])\n",
    "fitPipe('svm',text_clf_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d41b08bc0588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "1-m/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (1, 4), (2, 2), (2, 3), (2, 4), (3, 3), (3, 4)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([[(i,j) for j in range(i,4+1)] for i in range(1,3+1)],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', LinearSVC())\n",
    "])\n",
    "N_FEATURES_OPTIONS = [2, 4, 8]\n",
    "C_OPTIONS = [1, 10, 100, 1000]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "]\n",
    "reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "grid.fit(digits.data, digits.target)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Digit classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_digit_t_prd=grid.best_estimator_.predict(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(Y_digit_t_prd==digits.target)-len(Y_digit_t_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1-223/len(Y_digit_t_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.score(digits.data,digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mah echo algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class Echo(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X, *_):return X\n",
    "    def fit(self, *_):return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit: cpu was here\n",
      "transform: cpu was here\n",
      "futt\n",
      "transform: cpu was here\n",
      "0.909952606635071\n"
     ]
    }
   ],
   "source": [
    "text_clf_sgdE = Pipeline([('vect', CountVectorizer(stop_words='english',ngram_range=(1,3), )),\n",
    "                    # ('tfidf', TfidfTransformer()),\n",
    "                    ('echo',Echo()),\n",
    "                     ('clf',SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None))\n",
    "                    ])\n",
    "text_clf_sgdE.fit(X_train,Y_train)\n",
    "print(\"futt\")\n",
    "print(text_clf_sgdE.score(X_test,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
